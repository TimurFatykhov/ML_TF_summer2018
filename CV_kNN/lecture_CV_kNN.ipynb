{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center>Кросс-валидация, метод ближайших соседей"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <center>kNN - k Nearest Neighbours (метод ближайших соседей)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Это, наравне с деревом решений, один из самых понятных подходов к классификации. На уровне интуиции суть метода такова: посмотри на соседей, какие преобладают, таков и ты. Успех метода будет зависеть от хорошо подобранной метрики (способа измерения расстояния между объектами)\n",
    "\n",
    "Согласно методу ближайших соседей, тестовый пример (зеленый шарик) будет отнесен к классу \"синие\", а не \"красные\".\n",
    "\n",
    "<img src=\"./img/kNN.png\">\n",
    "\n",
    "Например, если не знаешь, какой тип товара указать в объявлении для Bluetooth-гарнитуры, можешь найти 5 похожих гарнитур, и если 4 из них отнесены к категории \"Аксессуары\", и только один - к категории \"Техника\", то здравый смысл подскажет для своего объявления тоже указать категорию \"Аксессуары\".\n",
    "\n",
    "Для классификации каждого из объектов тестовой выборки необходимо последовательно выполнить следующие операции:\n",
    " - Вычислить расстояние до каждого из объектов обучающей выборки\n",
    " - Отобрать $k$ объектов обучающей выборки, расстояние до которых минимально\n",
    " - Класс классифицируемого объекта — это класс, наиболее часто встречающийся среди $k$ ближайших соседей\n",
    " \n",
    " Примечательное свойство такого подхода  – его ленивость. Это значит, что вычисления начинаются только в момент классификации тестового примера, а заранее, только при  наличии обучающих примеров, никакая модель не строится. В этом отличие, например, от ранее рассмотренного дерева решений, где сначала на основе обучающей выборки строится дерево, а потом относительно быстро происходит классификация тестовых примеров. \n",
    " \n",
    "Стоит отметить, что метод ближайших соседей – хорошо изученный подход (в машинном обучении, эконометрике и статистике больше известно наверно только про линейную регрессию). Для метода ближайших соседей существует немало важных теорем, утверждающих, что на \"бесконечных\" выборках это оптимальный метод классификации. Авторы классической книги \"The Elements of Statistical Learning\" считают kNN теоретически идеальным алгоритмом, применимость которого просто ограничена вычислительными возможностями и проклятием размерностей. \n",
    "\n",
    "### Метод ближайших соседей в реальных задачах\n",
    "- В чистом виде kNN может послужить хорошим стартом (baseline) в решении какой-либо задачи;\n",
    "- В соревнованиях Kaggle kNN часто используется для построения мета-признаков (прогноз kNN подается на вход прочим моделям) или в стекинге/блендинге;\n",
    "- Идея ближайшего соседа расширяется и на другие задачи, например, в рекомендательных системах простым начальным решением может быть рекомендация какого-то товара (или услуги), популярного среди *ближайших соседей* человека, которому хотим сделать рекомендацию;\n",
    "- На практике для больших выборок часто пользуются *приближенными* методами поиска ближайших соседей. [Вот](https://www.youtube.com/watch?v=UUm4MOyVTnE) лекция Артема Бабенко про эффективные алгоритмы поиска ближайших соседей среди миллиардов объектов в пространствах высокой размерности (поиск по картинкам). Также известны открытые библиотеки, в которых реализованы такие алгоритмы, спасибо компании Spotify за ее библиотеку [Annoy](https://github.com/spotify/annoy).\n",
    "\n",
    "Качество классификации методом ближайших соседей зависит от нескольких параметров:\n",
    " - число соседей\n",
    " - метрика расстояния между объектами. Отметим, что при использовании большинства метрик значения признаков надо масштабировать. Условно говоря, чтобы признак \"Зарплата\" с диапазоном значений до 100 тысяч не вносил больший вклад в расстояние, чем \"Возраст\" со значениями до 100. \n",
    " - веса соседей (соседи тестового примера могут входить с разными весами, например, чем дальше пример, тем с меньшим коэффициентом учитывается его \"голос\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " \n",
    "### Класс KNeighborsClassifier в Scikit-learn\n",
    "Основные параметры класса sklearn.neighbors.KNeighborsClassifier:\n",
    " - weights: \"uniform\" (все веса равны), \"distance\" (вес обратно пропорционален расстоянию до тестового примера) или другая определенная пользователем функция\n",
    " - algorithm (опционально): \"brute\", \"ball_tree\", \"KD_tree\", или \"auto\". В первом случае ближайшие соседи для каждого тестового примера считаются перебором обучающей выборки. Во втором и третьем - расстояние между примерами хранятся в дереве, что ускоряет нахождение ближайших соседей. В случае указания параметра \"auto\" подходящий способ нахождения соседей будет выбран автматически на основе обучающей выборки.\n",
    " - leaf_size (опционально): порог переключения на полный перебор в случае выбора BallTree или KDTree для нахождения соседей\n",
    " - metric: \"minkowski\", \"manhattan\", \"euclidean\", \"chebyshev\" и другие"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <center>CrossValidation  (кросс-валидация)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Разобьем термин на составные части: \"кросс\" и \"валидация\". Кросс - означает крест-на-крест, а валидация не что иное, как проверка. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='./img/val_translate.png'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Получается, что дословно термин можно перевести как \"перекрестная проверка\" - и это почти правда, только крестов в ней никаких нет. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Кросс-валидацию* чаще используют для проверки обобщающих способностей модели (дерева, леса и т.д.) на бедных, малоразмерных выборках: то есть в ситуации, когда размер датасета не позволяет отложить 70% для обучения модели, и 30% для проверки ее работоспособности. Такое случается когда накопить большие датасеты достаточно дорого, или сложно, или невозможно в принципе. Например, если объектами нашего датасета будут являться сверхподъемные самосвалы \"Белаз\", которые выпускаются штучно, то длина *l* нашего датасета составит всего пару десятков (это первый пример, пришедший в голову, но таких может быть куча). \n",
    "<br>\n",
    "Предположим в вашем датасете всего лишь 300 объектов, если применить *holdout* к такой выборке (отложить какую то долю для проверки обобщающих способностей модели), например в 30%, то 210 объектов для обучения звучит довольно скудно, особенно в сравнении с 300. Если отложить 10%, то 30 объектов довольно мало, чтобы убедиться в работоспособности нашей модели.\n",
    "<br> \n",
    "В таких случаях и помогает *кросс-валидация*. Ее **идея** состоит в том, чтобы, разбивая несколько раз подряд выборку на train и valid, обучить модель несколько раз на \"разных\" train-ах и накопить значения метрики качества модели на соответствующих valid-ных частях, чтобы потом усреднить их и сделать вывод о том, насколько хорошо настроена наша модель (как хорошо подобраны гипер-параметры).\n",
    "<br>\n",
    "<br>\n",
    "Нагляднее картинкой:\n",
    "<br>\n",
    "<img src='./img/10_fold_cv.png'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Здесь выборку разбили на 10 частей. Сначала модель обучили на №2-№10 частях и вычислили *accuracy* для первой части. После отложили вторую часть, обучили модель на оставшихся и снова вычислили *accuracy* на отложенной части. И так продолжаем до тех пор, пока не получим десять значений *accuracy*. Затем, усреднив все полученный значения точности модели, мы получим финальную *accuracy*, по которой можно судить о обобщающих способностях модели с заданными гипер-параметрами."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Класс GridSearchCV в Scikit-learn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Основные параметры класса sklearn.model_selection.GridSearchCV\n",
    "- estimator - модель, реализующая scikit-learn интерфейс\n",
    "- param_grid - словарь или лист с параметрами, например: \n",
    "```python\n",
    "{'max_depth': range(1,11), 'max_features': range(4,19)}\n",
    "```\n",
    "- cv - количество фолдов (разбиений) или генератор кросс-валидации (например StratifiedKFold)\n",
    "- n_jobs - кол-во ядер, которое будет задействовано для рассчета (передайте -1 для того, чтобы нагрузить все что есть)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Пример использования"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV, StratifiedKFold, train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier, export_graphviz\n",
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./data/telecom_churn.csv')\n",
    "\n",
    "# немного подготовим датасет\n",
    "df['International plan'] = pd.factorize(df['International plan'])[0]\n",
    "df['Voice mail plan'] = pd.factorize(df['Voice mail plan'])[0]\n",
    "df['Churn'] = df['Churn'].astype('int')\n",
    "states = df['State']\n",
    "y = df['Churn']\n",
    "df.drop(['State', 'Churn'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, X_holdout, y_train, y_holdout = train_test_split(df.values, y, test_size=0.3, random_state=17)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# дерево, которое \"передадим в объект кросс-валидации\"\n",
    "tree = DecisionTreeClassifier()\n",
    "\n",
    "# генератор кросс-валидации с сохранение процентных соотношений в значениях целевой переменной\n",
    "skf = StratifiedKFold(n_splits=3, shuffle=True, random_state=17)\n",
    "\n",
    "# список параметров для перебора\n",
    "params = {'max_depth': range(2,11), 'max_features': range(4,9)}\n",
    "\n",
    "gs_tree = GridSearchCV(estimator=tree, param_grid=params, cv=skf, n_jobs=-1)\n",
    "gs_tree.fit(X=X_train, y=y_train);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs_tree.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_pred = gs_tree.best_estimator_.predict(X_holdout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_score(y_pred, y_holdout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export_graphviz(gs_tree.best_estimator_, feature_names=df.columns, out_file='./img/churn_tree.dot', filled=True)\n",
    "# !dot -Tpng ./img/churn_tree.dot -o ./img/churn_tree.png"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='./img/churn_tree.png'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "<font size=1>Автор: Тимур Фатыхов. <br>\n",
    "По материалам программиста-исследователя Mail.ru Group, старшего преподавателя Факультета Компьютерных Наук ВШЭ Юрия Кашницкого. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
